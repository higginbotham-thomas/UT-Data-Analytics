---
title: "Customer Brand Preferences Report"
output: html_notebook
---

Load the caret library

```{r}
library(caret)
library(C50)
library(erboost)
```

First, import and become familiar with the training set, "CompleteResponses.csv"

```{r}
CompleteResponses <- read.csv("CompleteResponses.csv", header=TRUE, sep=",")
```

Next, perform any necessary pre-processing

```{r}
#List the attributes within the data set

attributes(CompleteResponses)
```

```{r}
#Prints the min, max, mean, median, and quartiles of each attribute
summary(CompleteResponses)
```

There do not appear to be any missing values

```{r}
#Displays the structure of your data set
str(CompleteResponses)
```

```{r}
#Displays the attributes within your data set
names(CompleteResponses)
```

```{r}
#Will print out the instances within that particular column of your data set
CompleteResponses$elevel
```

```{r}
#histogram plot
hist(CompleteResponses$salary)
hist(CompleteResponses$age)
hist(CompleteResponses$elevel)
hist(CompleteResponses$car)
hist(CompleteResponses$zipcode)
hist(CompleteResponses$credit)
hist(CompleteResponses$brand)
```

1.  There are more responses from 20-30 than any other age group
2.  There are twice as many BMW owners that any other make of car
3.  More of the responses favor Sony vs. Acer
4.  Otherwise, the frequency for Salary, Education Level, and Zip Code is spread pretty evenly throughout the histogram groups

```{r}
#scatter (box) plot
plot(CompleteResponses$salary,CompleteResponses$brand)
plot(CompleteResponses$age,CompleteResponses$brand)
plot(CompleteResponses$elevel,CompleteResponses$brand)
plot(CompleteResponses$car,CompleteResponses$brand)
plot(CompleteResponses$zipcode,CompleteResponses$brand)
plot(CompleteResponses$credit,CompleteResponses$brand)
```

It appears that there may be a preference for Sony over Acer as the salary of the customer increases.

```{r}
#normal quintile plot to see if data is normally distributed
qqnorm(CompleteResponses$salary)
qqnorm(CompleteResponses$age)
qqnorm(CompleteResponses$elevel)
qqnorm(CompleteResponses$car)
qqnorm(CompleteResponses$zipcode)
qqnorm(CompleteResponses$credit)
qqnorm(CompleteResponses$brand)
```

The data appears to be normally distributed

Brand (of computer) will be the dependent variable

```{r}
#Convert brand to a 2 level factor
CompleteResponses$brand <- as.factor(CompleteResponses$brand)
```

Now, create the training and test sets using createDataPartition

```{r}
#set the seed
set.seed(123)
```

```{r}
#define a 75%/25% train/test split of the dataset
inTraining <- createDataPartition(CompleteResponses$brand, p=.75, list=FALSE)
training <- CompleteResponses[inTraining,]
testing <- CompleteResponses[-inTraining,]
```

Next, build a model using Stochastic Gradient Boosting (GBM), on the training set with 10-fold cross-validation and an Automatic Tuning Grid. This will be used to predict nominal data (a customer's computer brand preference)

```{r}
#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)
```

```{r}
#train the GBM model
GBMFit1 <- train(brand~., data=training, method="gbm", trControl=fitControl, nTrain=round(nrow(training)*.75))
```

```{r}
#training results
GBMFit1
```

```{r}
#use varImp to ascertain how the model priortized each feature in the training
importance <- varImp(GBMFit1)
```

```{r}
importance
```

The two most important variables, according to the scores from varImp, are salary and age

Now, use C5.0 to train a model with 10-fold cross-validation.

```{r}
C50Fit1 <- train(brand~., data = training, method = "C5.0", trControl=fitControl, verbose=FALSE)
```
```{r}
C50Fit1
```

Using C5.0, the best results were using trials = 20, model = rules, and winnow = FALSE,
which is:
Accuracy    0.9158144  
Kappa       0.8210332

Now show the most important variables
```{r}
importance = varImp(C50Fit1)
```

```{r}
importance
```

Using C5.0, the most important variables are Salary, Age, and Car

```{r}
rfFit1 <- train(brand~., data = training, method = "rf", trControl=fitControl, tunelength = 5)
```

```{r}
rfFit1
```

Now, ascertain how the model prioritized each feature in the training using varImp

```{r}
importance = varImp(rfFit1)
```

```{r}
importance
```

Using Random Forest, the two most important variables are salary and age.

Now, train a model 

```{r}

```

Using Random Forest, the two most important variables are salary and age.

Now, predict product performance:

I will use the Random Forest trained model as this was the one that had both the highest accuracy and Kappa scores.

```{r}
#use predict() against the surveyIncomplete data set
SurveyIncomplete <- read.csv("SurveyIncomplete.csv", header=TRUE, sep=",")

rfClasses <- predict(rfFit1, SurveyIncomplete)
```

```{r}
#CompleteResponses <- read.csv("CompleteResponses.csv", header=TRUE, sep=",")
metrics <- postResample(rfClasses, testing$brand)
```

Using postResample to compare predicted values (rfClasses) and observed values (testing$brand) to show the overall agreement rate and Kappa

```{r}
metrics
```

Accuracy and Kappa are both down from the rfFit1 values where mtry = 4:

Result    Accuracy      Kappa
rfFit1    0.9197206     0.8295246
metrics   0.54324980    0.02819453 

```{r}
summary(rfClasses)
```

37.6% of the responses were for Acer in the predicted set

```{r}
summary(CompleteResponses$brand)
```

37.8% of the responses were for Acer in the Complete Responses set

Overall, the results are very similar between the predicted and complete responses sets.

```{r}
# Add the predicted results to SurveyIncomplete$brand
SurveyIncomplete$brand <- rfClasses
```

```{r}
#Write out the PredictedResponses data frame to csv
write.csv(SurveyIncomplete,"PredictedResponses.csv")
```

```{r}
#combine the CompleteResponses and SurveyIncomplete dataframes
TotalResponses <- rbind(CompleteResponses, SurveyIncomplete)
```

```{r}
#Write out the TotalResponses data frame to csv
write.csv(TotalResponses,"TotalResponses.csv")
```

